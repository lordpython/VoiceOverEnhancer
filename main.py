import asyncio
import streamlit as st
from utils.api_clients import (fetch_transcript, enhance_text, text_to_speech,
                               get_available_voices)
from utils.audio_processor import combine_audio_chunks, chunk_text
from utils.cache_manager import CacheManager
from config import MAX_CHUNK_LENGTH, CONCURRENT_TASKS

# Initialize cache manager
cache_manager = CacheManager()


def init_session_state():
    """Initialize session state variables"""
    if 'processing' not in st.session_state:
        st.session_state.processing = False
    if 'progress' not in st.session_state:
        st.session_state.progress = 0


async def process_chunks(chunks: list, voice_id: str,
                         voice_settings: dict) -> bytes:
    """Process text chunks concurrently"""
    sem = asyncio.Semaphore(CONCURRENT_TASKS)
    audio_chunks = []
    progress_bar = st.progress(0)

    async def process_chunk(chunk: str) -> bytes:
        async with sem:
            enhanced = await enhance_text(chunk)
            audio = await text_to_speech(
                enhanced,
                voice_id,
                stability=voice_settings['stability'],
                similarity_boost=voice_settings['similarity_boost'],
                style=voice_settings['style'],
                use_speaker_boost=voice_settings['speaker_boost'])
            return audio if audio else b""

    tasks = [process_chunk(chunk) for chunk in chunks]
    total_chunks = len(tasks)

    for i, task in enumerate(asyncio.as_completed(tasks), 1):
        chunk_audio = await task
        if chunk_audio:
            audio_chunks.append(chunk_audio)
        progress = (i / total_chunks) * 100
        progress_bar.progress(int(progress))
        st.session_state.progress = progress

    return combine_audio_chunks(audio_chunks)


async def main():
    st.set_page_config(page_title="Ù…Ø­ÙˆÙ„ Ù†ØµÙˆØµ ÙŠÙˆØªÙŠÙˆØ¨ Ø¥Ù„Ù‰ ÙƒÙ„Ø§Ù…",
                       page_icon="ğŸ¤",
                       layout="wide")

    # Add CSS for RTL support
    st.markdown("""
        <style>
        .stTextInput, .stSelectbox, .stSlider, .stCheckbox {
            direction: rtl;
            text-align: right;
        }
        .css-1inwz65 {
            direction: rtl;
            text-align: right;
        }
        </style>
    """,
                unsafe_allow_html=True)

    init_session_state()

    st.title("ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø§Ù„Ù‰ ØªØ¹Ù„ÙŠÙ‚ ØµÙˆØªÙŠ")
    st.markdown("ØªØ­ÙˆÙŠÙ„ Ù†ØµÙˆØµ ÙØ¯ÙŠÙˆØ§Øª ÙŠÙˆØªÙŠÙˆØ¨ Ø¥Ù„Ù‰ ØªØ¹Ù„ÙŠÙ‚ ØµÙˆØªÙŠ.")

    # Input section
    col1, col2 = st.columns([2, 1])
    with col1:
        video_url = st.text_input(
            "Ø±Ø§Ø¨Ø· ÙÙŠØ¯ÙŠÙˆ ÙŠÙˆØªÙŠÙˆØ¨",
            placeholder="https://www.youtube.com/watch?v=...")

    # Voice selection and settings
    voices = await get_available_voices()
    if not voices:
        st.error("ÙØ´Ù„Øª Ø§Ù„Ø¹Ù…Ù„ÙŠØ© ÙŠØ§ Ø§Ù†Ù‡ Ø§Ù„ÙØ¯ÙŠÙˆ Ø¨Ø·Ø§Ø· Ø§Ùˆ ØªØ¯Ù‚ Ø¹Ù„Ù‰ ÙŠÙˆØ³Ù ")
        return

    voice_options = {voice["name"]: voice["id"] for voice in voices}

    with col2:
        selected_voice = st.selectbox("Ø´ÙˆÙÙ„Ùƒ ÙˆØ§Ø­Ø¯ ØµÙˆØªÙ‡ Ø·ÙŠØ¨",
                                      options=list(voice_options.keys()))

    # Voice configuration section
    st.subheader("Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙˆØª")
    col3, col4, col5 = st.columns(3)

    with col3:
        stability = st.slider(
            "Ø§Ù„Ø«Ø¨Ø§Øª",
            min_value=0.0,
            max_value=1.0,
            value=0.5,
            help="ØªØ¹Ù„ÙŠÙŠÙ‡ ÙŠØ«Ø¨Øª Ø§Ù„ØµÙˆØª ØªÙ‚Ù„Ù„ Ù…Ø§Ø¯Ø±ÙŠ Ø¹Ø§Ø¯ Ø´ÙŠØµÙŠØ± Ø¨Ø§Ù„Ø¶Ø¨Ø·")

        style = st.slider(
            "Ø§Ù„Ù†Ù…Ø·",
            min_value=0.0,
            max_value=1.0,
            value=0.0,
            help="Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø£Ø¹Ù„Ù‰ ØªØ¹Ø²Ø² Ø§Ù„Ù†Ù…Ø· ÙˆØ§Ù„Ù…Ø´Ø§Ø¹Ø± ÙˆÙ„ÙƒÙ† Ù‚Ø¯ ØªØ¤Ø«Ø± Ø¹Ù„Ù‰ Ø§Ù„ØªÙ…Ø§Ø³Ùƒ")

    with col4:
        similarity_boost = st.slider(
            "ØªØ¹Ø²ÙŠØ² Ø§Ù„ØªØ´Ø§Ø¨Ù‡",
            min_value=0.0,
            max_value=1.0,
            value=0.75,
            help=
            "Ø§Ø°Ø§ Ø²Ø¯Øª Ø¨Ù‡Ø°Ø§ Ø§Ù„ØµØ©Øª Ø±Ø§Ø­ ÙŠØµÙŠØ± Ù†ÙØ³ Ø§Ù„ØµÙˆØª Ø§Ù„ØµØ¬ÙŠ Ø§Ø°Ø§ Ù…Ø§ÙƒØ§Ù† ÙÙŠ ØµÙˆØª ØµØ¬ÙŠ Ø¨Ø§Ù„Ø§Ø³Ø§Ø³ ÙŠÙ…ÙƒÙ† ÙŠØ·Ù„Ø¹Ù„Ùƒ Ø§Ù„Ù„ÙŠ ÙŠÙ‚ÙˆÙ„ ÙˆÙ„Ùƒ Ø§Ù„ÙˆÙˆÙˆÙ‡"
        )

    with col5:
        speaker_boost = st.checkbox(
            "ØªØ¹Ø²ÙŠØ² Ø§Ù„ØµÙˆØª",
            value=True,
            help="ØªØ­Ø³ÙŠÙ† ÙˆØ¶ÙˆØ­ Ø§Ù„ØµÙˆØª ÙˆØªÙ‚Ù„ÙŠÙ„ Ø¶ÙˆØ¶Ø§Ø¡ Ø§Ù„Ø®Ù„ÙÙŠØ©")

    voice_settings = {
        'stability': stability,
        'similarity_boost': similarity_boost,
        'style': style,
        'speaker_boost': speaker_boost
    }

    if st.button("ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ ÙƒÙ„Ø§Ù…", disabled=st.session_state.processing):
        if not video_url:
            st.error("Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø¯Ø®Ø§Ù„ Ø±Ø§Ø¨Ø· ÙÙŠØ¯ÙŠÙˆ ÙŠÙˆØªÙŠÙˆØ¨")
            return

        st.session_state.processing = True
        try:
            with st.spinner("Ø¬Ø§Ø±Ù Ù…Ø¹Ø§Ù„Ø¬Ø© Ù†Øµ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ..."):
                # Fetch and process transcript
                transcript = await fetch_transcript(video_url)
                text = " ".join(item["text"] for item in transcript)
                chunks = chunk_text(text, MAX_CHUNK_LENGTH)

                # Process chunks and generate audio
                voice_id = voice_options[selected_voice]
                audio_data = await process_chunks(chunks, voice_id,
                                                  voice_settings)

                # Display audio player and download button
                st.audio(audio_data, format="audio/mp3")
                st.download_button(label="ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØª",
                                   data=audio_data,
                                   file_name="transcript_audio.mp3",
                                   mime="audio/mp3")

        except ValueError as e:
            st.error(str(e))
        except Exception as e:
            st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹: {str(e)}")
        finally:
            st.session_state.processing = False
            st.session_state.progress = 0


if __name__ == "__main__":
    asyncio.run(main())
